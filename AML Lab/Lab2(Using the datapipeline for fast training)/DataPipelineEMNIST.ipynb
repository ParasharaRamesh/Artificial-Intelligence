{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "This code is to show the use of the DNNClassifier estimator for classification of EMNIST data by using the Data pipeline API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow.feature_column as fc\n",
    "import csv\n",
    "import sys\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import gzip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# file_path=os.path.join(DATASET_PATH,\"ds3.csv\")\n",
    "BATCH_SIZE=32\n",
    "STEPS=1000\n",
    "NUM_EPOCHS=40\n",
    "shuffle_buffer_size=70000\n",
    "prefetch_buffer_size=32\n",
    "num_classes= 62\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _parse_function(filename, label):\n",
    "    image_string = tf.read_file(filename)\n",
    "\n",
    "    # Don't use tf.image.decode_image, or the output shape will be undefined\n",
    "    image = tf.image.decode_jpeg(image_string, channels=1)\n",
    "\n",
    "    # This will convert to float values in [0, 1]\n",
    "    image = tf.image.convert_image_dtype(image, tf.float32)\n",
    "\n",
    "    #image = tf.image.resize_images(image, [64, 64])\n",
    "    return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def input_fn():\n",
    "    mapping = pd.read_csv(\"train-labels.csv\", header = None)\n",
    "    \n",
    "    filenames = list(mapping.iloc[:,0])\n",
    "    labels = list(mapping.iloc[:,1])\n",
    "    \n",
    "    parse_fn = lambda f, l: _parse_function(f, l)\n",
    "    \n",
    "    dataset = tf.data.Dataset.from_tensor_slices((filenames, labels))\n",
    "    dataset = dataset.shuffle(len(filenames))\n",
    "    dataset = dataset.map(parse_fn, num_parallel_calls=4)\n",
    "    #dataset = dataset.map(train_preprocess, num_parallel_calls=4)\n",
    "    dataset = dataset.repeat(5)\n",
    "    dataset = dataset.batch(64)\n",
    "    dataset = dataset.prefetch(1)\n",
    "    \n",
    "    \n",
    "    iterator = dataset.make_one_shot_iterator()\n",
    "    images, labels = iterator.get_next()\n",
    "    #iterator = dataset.make_initializable_iterator()\n",
    "    #images, labels = iterator.get_next()\n",
    "    #iterator_init_op = iterator.initializer\n",
    "    \n",
    "    #inputs = {'images': images, 'labels': labels, 'iterator_init_op': iterator_init_op}\n",
    "    return {\"images\": images}, labels\n",
    "\n",
    "def test_input_fn():\n",
    "    mapping = pd.read_csv(\"test-labels.csv\", header = None)\n",
    "    filenames = list(mapping.iloc[:,0])\n",
    "    labels = list(mapping.iloc[:,1])\n",
    "    \n",
    "    parse_fn = lambda f, l: _parse_function(f, l)\n",
    "    \n",
    "    dataset = tf.data.Dataset.from_tensor_slices((filenames, labels))\n",
    "    dataset = dataset.map(parse_fn, num_parallel_calls=4)\n",
    "    #dataset = dataset.repeat(2)\n",
    "    dataset = dataset.batch(64)\n",
    "    dataset = dataset.prefetch(1)\n",
    "    \n",
    "    \n",
    "    iterator = dataset.make_one_shot_iterator()\n",
    "    images, labels = iterator.get_next()\n",
    "    #iterator = dataset.make_initializable_iterator()\n",
    "    #images, labels = iterator.get_next()\n",
    "    #iterator_init_op = iterator.initializer\n",
    "    \n",
    "    #inputs = {'images': images, 'labels': labels, 'iterator_init_op': iterator_init_op}\n",
    "    return {\"images\": images}, labels\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_dnn_classifier(hidden_units=None):\n",
    "    feature_cols=[fc.numeric_column(\"images\", shape=[784])]\n",
    "    estimator = tf.estimator.DNNClassifier(feature_columns=feature_cols,hidden_units = hidden_units,activation_fn=tf.nn.relu,n_classes=num_classes,model_dir=\"./model_checkpoints\")\n",
    "    return estimator  \n",
    "\n",
    "def train_dnn_classifier(steps,hidden_units=None):\n",
    "    estimator = build_dnn_classifier(hidden_units)\n",
    "    print(\"Model Built!\")\n",
    "    estimator.train(input_fn = input_fn,steps=steps)\n",
    "    print(\"Finished Training!\")\n",
    "    return estimator\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "INFO:tensorflow:Using config: {'_global_id_in_cluster': 0, '_log_step_count_steps': 100, '_num_worker_replicas': 1, '_num_ps_replicas': 0, '_keep_checkpoint_every_n_hours': 10000, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x0000022856737D68>, '_is_chief': True, '_session_config': None, '_save_checkpoints_steps': None, '_train_distribute': None, '_task_id': 0, '_device_fn': None, '_tf_random_seed': None, '_save_checkpoints_secs': 600, '_service': None, '_evaluation_master': '', '_task_type': 'worker', '_keep_checkpoint_max': 5, '_master': '', '_save_summary_steps': 100, '_model_dir': './model_checkpoints'}\n",
      "Model Built!\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from ./model_checkpoints\\model.ckpt-5000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Saving checkpoints for 5000 into ./model_checkpoints\\model.ckpt.\n",
      "INFO:tensorflow:loss = 31.56245, step = 5001\n",
      "INFO:tensorflow:global_step/sec: 32.5194\n",
      "INFO:tensorflow:loss = 41.502754, step = 5101 (3.077 sec)\n",
      "INFO:tensorflow:global_step/sec: 38.3094\n",
      "INFO:tensorflow:loss = 34.739357, step = 5201 (2.610 sec)\n",
      "INFO:tensorflow:global_step/sec: 41.1912\n",
      "INFO:tensorflow:loss = 44.13156, step = 5301 (2.428 sec)\n",
      "INFO:tensorflow:global_step/sec: 39.8238\n",
      "INFO:tensorflow:loss = 48.528492, step = 5401 (2.511 sec)\n",
      "INFO:tensorflow:global_step/sec: 35.4272\n",
      "INFO:tensorflow:loss = 32.545414, step = 5501 (2.822 sec)\n",
      "INFO:tensorflow:global_step/sec: 37.383\n",
      "INFO:tensorflow:loss = 35.06616, step = 5601 (2.677 sec)\n",
      "INFO:tensorflow:global_step/sec: 37.2112\n",
      "INFO:tensorflow:loss = 42.33485, step = 5701 (2.687 sec)\n",
      "INFO:tensorflow:global_step/sec: 38.8882\n",
      "INFO:tensorflow:loss = 34.005257, step = 5801 (2.570 sec)\n",
      "INFO:tensorflow:global_step/sec: 36.5398\n",
      "INFO:tensorflow:loss = 29.27528, step = 5901 (2.736 sec)\n",
      "INFO:tensorflow:global_step/sec: 39.3571\n",
      "INFO:tensorflow:loss = 33.539627, step = 6001 (2.542 sec)\n",
      "INFO:tensorflow:global_step/sec: 38.2249\n",
      "INFO:tensorflow:loss = 23.153753, step = 6101 (2.615 sec)\n",
      "INFO:tensorflow:global_step/sec: 38.6856\n",
      "INFO:tensorflow:loss = 36.3857, step = 6201 (2.585 sec)\n",
      "INFO:tensorflow:global_step/sec: 39.3863\n",
      "INFO:tensorflow:loss = 24.775505, step = 6301 (2.540 sec)\n",
      "INFO:tensorflow:global_step/sec: 39.3742\n",
      "INFO:tensorflow:loss = 31.891666, step = 6401 (2.540 sec)\n",
      "INFO:tensorflow:global_step/sec: 39.4359\n",
      "INFO:tensorflow:loss = 23.46495, step = 6501 (2.535 sec)\n",
      "INFO:tensorflow:global_step/sec: 37.5706\n",
      "INFO:tensorflow:loss = 40.246456, step = 6601 (2.662 sec)\n",
      "INFO:tensorflow:global_step/sec: 38.9462\n",
      "INFO:tensorflow:loss = 27.381329, step = 6701 (2.569 sec)\n",
      "INFO:tensorflow:global_step/sec: 37.6813\n",
      "INFO:tensorflow:loss = 39.25434, step = 6801 (2.668 sec)\n",
      "INFO:tensorflow:global_step/sec: 35.6151\n",
      "INFO:tensorflow:loss = 33.254993, step = 6901 (2.793 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 7000 into ./model_checkpoints\\model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 31.992867.\n",
      "Finished Training!\n"
     ]
    }
   ],
   "source": [
    "est=train_dnn_classifier(2000, hidden_units=[512,256,128,64])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict():\n",
    "    preds=[]\n",
    "    predictions = est.predict(input_fn=test_input_fn)\n",
    "    for prediction in predictions:\n",
    "        preds.append(prediction[\"class_ids\"][0])\n",
    "    return preds\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from ./model_checkpoints\\model.ckpt-7000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n"
     ]
    }
   ],
   "source": [
    "preds=predict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test-labels.csv - contains the mappings of the filenames to thier labels# test-l \n",
    "mapping = pd.read_csv(\"test-labels.csv\", header = None)\n",
    "\n",
    "# actual labels\n",
    "actual = list(mapping.iloc[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15000 15000\n"
     ]
    }
   ],
   "source": [
    "print(len(actual),len(preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_accuracy():\n",
    "    act = tf.placeholder(tf.int64, shape = [15000])\n",
    "    pred = tf.placeholder(tf.int64, shape = [15000])\n",
    "    \n",
    "    acc = tf.metrics.accuracy(labels=act, predictions=pred)[1]\n",
    "    with tf.Session() as sess:\n",
    "        #sess.graph._unsafe_unfinalize()\n",
    "        sess.run(tf.local_variables_initializer())\n",
    "        sess.run(tf.global_variables_initializer())\n",
    "        res=sess.run([acc], feed_dict={act: actual, pred: preds})[0]\n",
    "    return res\n",
    "\n",
    "def my_precision():\n",
    "    act = tf.placeholder(tf.int64, shape = [15000])\n",
    "    pred = tf.placeholder(tf.int64, shape = [15000])\n",
    "    \n",
    "    prec = tf.metrics.precision(labels=act, predictions=pred)[1]\n",
    "    with tf.Session() as sess:\n",
    "        #sess.graph._unsafe_unfinalize()\n",
    "        sess.run(tf.local_variables_initializer())\n",
    "        sess.run(tf.global_variables_initializer())\n",
    "        res=sess.run([prec], feed_dict={act: actual, pred: preds})[0]\n",
    "    return res\n",
    "\n",
    "\n",
    "def my_recall():\n",
    "    act = tf.placeholder(tf.int64, shape = [15000])\n",
    "    pred = tf.placeholder(tf.int64, shape = [15000])\n",
    "    \n",
    "    rec = tf.metrics.recall(labels=act, predictions=pred)[1]\n",
    "    with tf.Session() as sess:\n",
    "        #sess.graph._unsafe_unfinalize()\n",
    "        sess.run(tf.local_variables_initializer())\n",
    "        sess.run(tf.global_variables_initializer())\n",
    "        res=sess.run([rec], feed_dict={act: actual, pred: preds})[0]\n",
    "    return res\n",
    "\n",
    "def my_confusion_matrix():\n",
    "    act = tf.placeholder(tf.int64, shape = [15000])\n",
    "    pred = tf.placeholder(tf.int64, shape = [15000])\n",
    "    \n",
    "    confmat = tf.confusion_matrix(labels=act, predictions=pred)[1]\n",
    "    with tf.Session() as sess:\n",
    "        #sess.graph._unsafe_unfinalize()\n",
    "        sess.run(tf.local_variables_initializer())\n",
    "        sess.run(tf.global_variables_initializer())\n",
    "        res=sess.run([confmat], feed_dict={act: actual, pred: preds})[0]\n",
    "    return res\n",
    "\n",
    "def my_recall_class():\n",
    "    acts_k = tf.placeholder(tf.int64, shape = [None])\n",
    "    preds_k = tf.placeholder(tf.int64, shape = [None])\n",
    "    recall_k, recall_op_k = tf.metrics.recall(labels=acts_k, predictions=preds_k)\n",
    "    \n",
    "    act_pred={n:[] for n in range(62)}\n",
    "\n",
    "    \n",
    "    for i in range(15000):#for all the test images do the following\n",
    "        k=actual[i]\n",
    "        act_pred[k].append((actual[i],preds[i]))\n",
    "    \n",
    "    \n",
    "    with tf.Session() as sess:\n",
    "        sess.run(tf.local_variables_initializer())\n",
    "        sess.run(tf.global_variables_initializer())\n",
    "        for k in range(62):\n",
    "            temp = act_pred[k]\n",
    "            temp2 = list(zip(*temp))\n",
    "            actual_k=list(temp2[0])\n",
    "            pred_k=list(temp2[1])\n",
    "            print(k, \"   : \", end = \" \")\n",
    "            print(sess.run([recall_k, recall_op_k], feed_dict={acts_k: actual_k, preds_k: pred_k}))\n",
    "\n",
    "            \n",
    "def my_precision_class():\n",
    "    acts_k = tf.placeholder(tf.int64, shape = [None])\n",
    "    preds_k = tf.placeholder(tf.int64, shape = [None])\n",
    "    precision_k, precision_op_k = tf.metrics.recall(labels=acts_k, predictions=preds_k)\n",
    "    \n",
    "    act_pred={n:[] for n in range(62)}\n",
    "\n",
    "    \n",
    "    for i in range(15000):#for all the test images do the following\n",
    "        k=actual[i]\n",
    "        act_pred[k].append((actual[i],preds[i]))\n",
    "    \n",
    "    \n",
    "    with tf.Session() as sess:\n",
    "        sess.run(tf.local_variables_initializer())\n",
    "        sess.run(tf.global_variables_initializer())\n",
    "        for k in range(62):\n",
    "            temp = act_pred[k]\n",
    "            temp2 = list(zip(*temp))\n",
    "            actual_k=list(temp2[0])\n",
    "            pred_k=list(temp2[1])\n",
    "            print(k, \"   : \", end = \" \")\n",
    "            print(sess.run([precision_k, precision_op_k], feed_dict={acts_k: actual_k, preds_k: pred_k}))\n",
    "\n",
    "            \n",
    "def evaluate_metrics():\n",
    "    acc=my_accuracy()\n",
    "    prec=my_precision()\n",
    "    rec=my_recall()\n",
    "    confmat=my_confusion_matrix()\n",
    "    \n",
    "    print(\"METRICS ARE:\")\n",
    "    metrics={\"accuracy\":acc,\"precsion\":prec,\"recall\":rec,\"confusion_matrix\":confmat}\n",
    "    print(metrics)\n",
    "    \n",
    "    print(\"PER CLASS RECALL IS\")\n",
    "    my_recall_class() \n",
    "   \n",
    "    print(\"PER CLASS PRECISION IS\")\n",
    "    my_precision_class() \n",
    "\n",
    "#     Try the add_metrics function later!\n",
    "#     estimator=est\n",
    "#     estimator = tf.contrib.estimator.add_metrics(estimator, my_accuracy)\n",
    "#     estimator = tf.contrib.estimator.add_metrics(estimator, my_precision)\n",
    "#     estimator = tf.contrib.estimator.add_metrics(estimator, my_recall)\n",
    "#     estimator = tf.contrib.estimator.add_metrics(estimator, my_confusion_matrix)\n",
    "#     #estimator = tf.contrib.estimator.add_metrics(estimator, my_recall_class)  \n",
    "#     metrics=estimator.evaluate(input_fn=input_fn)\n",
    "#     return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "METRICS ARE:\n",
      "{'confusion_matrix': array([  0, 734,   2,   0,   0,   0,   0,   0,   1,   0,   0,   0,   0,\n",
      "         0,   0,   1,   0,   0,  24,   0,   0,   1,   0,   0,   0,   0,\n",
      "         0,   0,   0,   0,   0,   0,   0,   0,   3,   0,   0,   0,   0,\n",
      "         0,   0,   0,   0,   0,   2,   1,   1,  89,   0,   0,   0,   0,\n",
      "         0,   1,   0,   1,   0,   0,   0,   0,   0,   0]), 'accuracy': 0.7974, 'precsion': 0.98813474, 'recall': 0.9801051}\n",
      "PER CLASS RECALL IS\n",
      "0    :  [0.0, 0.0]\n",
      "1    :  [0.0, 1.0]\n",
      "2    :  [1.0, 1.0]\n",
      "3    :  [1.0, 0.99958557]\n",
      "4    :  [0.99958557, 0.9996846]\n",
      "5    :  [0.9996846, 0.9997374]\n",
      "6    :  [0.9997374, 0.9997792]\n",
      "7    :  [0.9997792, 0.9998129]\n",
      "8    :  [0.9998129, 0.9996701]\n",
      "9    :  [0.9996701, 0.99970603]\n",
      "10    :  [0.99970603, 0.9997118]\n",
      "11    :  [0.9997118, 0.9991464]\n",
      "12    :  [0.9991464, 0.9990338]\n",
      "13    :  [0.9990338, 0.99754435]\n",
      "14    :  [0.99754435, 0.9975829]\n",
      "15    :  [0.9975829, 0.99765074]\n",
      "16    :  [0.99765074, 0.99740696]\n",
      "17    :  [0.99740696, 0.997426]\n",
      "18    :  [0.997426, 0.997505]\n",
      "19    :  [0.997505, 0.9975333]\n",
      "20    :  [0.9975333, 0.9975493]\n",
      "21    :  [0.9975493, 0.99757695]\n",
      "22    :  [0.99757695, 0.9976286]\n",
      "23    :  [0.9976286, 0.9976763]\n",
      "24    :  [0.9976763, 0.9743506]\n",
      "25    :  [0.9743506, 0.9748603]\n",
      "26    :  [0.9748603, 0.9743781]\n",
      "27    :  [0.9743781, 0.97470486]\n",
      "28    :  [0.97470486, 0.9757845]\n",
      "29    :  [0.9757845, 0.97626114]\n",
      "30    :  [0.97626114, 0.9765489]\n",
      "31    :  [0.9765489, 0.97677976]\n",
      "32    :  [0.97677976, 0.9769995]\n",
      "33    :  [0.9769995, 0.97714233]\n",
      "34    :  [0.97714233, 0.9773911]\n",
      "35    :  [0.9773911, 0.9775229]\n",
      "36    :  [0.9775229, 0.97772527]\n",
      "37    :  [0.97772527, 0.97795373]\n",
      "38    :  [0.97795373, 0.9778694]\n",
      "39    :  [0.9778694, 0.978301]\n",
      "40    :  [0.978301, 0.97924197]\n",
      "41    :  [0.97924197, 0.9793409]\n",
      "42    :  [0.9793409, 0.97948164]\n",
      "43    :  [0.97948164, 0.9798087]\n",
      "44    :  [0.9798087, 0.979904]\n",
      "45    :  [0.979904, 0.9798881]\n",
      "46    :  [0.9798881, 0.97997737]\n",
      "47    :  [0.97997737, 0.9805093]\n",
      "48    :  [0.9805093, 0.98059165]\n",
      "49    :  [0.98059165, 0.9809407]\n",
      "50    :  [0.9809407, 0.97849876]\n",
      "51    :  [0.97849876, 0.9785225]\n",
      "52    :  [0.9785225, 0.9786396]\n",
      "53    :  [0.9786396, 0.9790972]\n",
      "54    :  [0.9790972, 0.97918206]\n",
      "55    :  [0.97918206, 0.97966224]\n",
      "56    :  [0.97966224, 0.9796751]\n",
      "57    :  [0.9796751, 0.9797605]\n",
      "58    :  [0.9797605, 0.9798496]\n",
      "59    :  [0.9798496, 0.9799279]\n",
      "60    :  [0.9799279, 0.9800141]\n",
      "61    :  [0.9800141, 0.9801051]\n",
      "PER CLASS PRECISION IS\n",
      "0    :  [0.0, 0.0]\n",
      "1    :  [0.0, 1.0]\n",
      "2    :  [1.0, 1.0]\n",
      "3    :  [1.0, 0.99958557]\n",
      "4    :  [0.99958557, 0.9996846]\n",
      "5    :  [0.9996846, 0.9997374]\n",
      "6    :  [0.9997374, 0.9997792]\n",
      "7    :  [0.9997792, 0.9998129]\n",
      "8    :  [0.9998129, 0.9996701]\n",
      "9    :  [0.9996701, 0.99970603]\n",
      "10    :  [0.99970603, 0.9997118]\n",
      "11    :  [0.9997118, 0.9991464]\n",
      "12    :  [0.9991464, 0.9990338]\n",
      "13    :  [0.9990338, 0.99754435]\n",
      "14    :  [0.99754435, 0.9975829]\n",
      "15    :  [0.9975829, 0.99765074]\n",
      "16    :  [0.99765074, 0.99740696]\n",
      "17    :  [0.99740696, 0.997426]\n",
      "18    :  [0.997426, 0.997505]\n",
      "19    :  [0.997505, 0.9975333]\n",
      "20    :  [0.9975333, 0.9975493]\n",
      "21    :  [0.9975493, 0.99757695]\n",
      "22    :  [0.99757695, 0.9976286]\n",
      "23    :  [0.9976286, 0.9976763]\n",
      "24    :  [0.9976763, 0.9743506]\n",
      "25    :  [0.9743506, 0.9748603]\n",
      "26    :  [0.9748603, 0.9743781]\n",
      "27    :  [0.9743781, 0.97470486]\n",
      "28    :  [0.97470486, 0.9757845]\n",
      "29    :  [0.9757845, 0.97626114]\n",
      "30    :  [0.97626114, 0.9765489]\n",
      "31    :  [0.9765489, 0.97677976]\n",
      "32    :  [0.97677976, 0.9769995]\n",
      "33    :  [0.9769995, 0.97714233]\n",
      "34    :  [0.97714233, 0.9773911]\n",
      "35    :  [0.9773911, 0.9775229]\n",
      "36    :  [0.9775229, 0.97772527]\n",
      "37    :  [0.97772527, 0.97795373]\n",
      "38    :  [0.98209304, 0.9778694]\n",
      "39    :  [0.9778694, 0.978301]\n",
      "40    :  [0.978301, 0.97924197]\n",
      "41    :  [0.97924197, 0.9793409]\n",
      "42    :  [0.9793409, 0.97948164]\n",
      "43    :  [0.97948164, 0.9798087]\n",
      "44    :  [0.9798087, 0.979904]\n",
      "45    :  [0.979904, 0.9798881]\n",
      "46    :  [0.9798881, 0.97997737]\n",
      "47    :  [0.97997737, 0.9805093]\n",
      "48    :  [0.9805093, 0.98059165]\n",
      "49    :  [0.98059165, 0.9809407]\n",
      "50    :  [0.9809407, 0.97849876]\n",
      "51    :  [0.97849876, 0.9785225]\n",
      "52    :  [0.9785225, 0.9786396]\n",
      "53    :  [0.9786396, 0.9790972]\n",
      "54    :  [0.9790972, 0.97918206]\n",
      "55    :  [0.97918206, 0.97966224]\n",
      "56    :  [0.97966224, 0.9796751]\n",
      "57    :  [0.9796751, 0.9797605]\n",
      "58    :  [0.9797605, 0.9798496]\n",
      "59    :  [0.9798496, 0.9799279]\n",
      "60    :  [0.9799279, 0.9800141]\n",
      "61    :  [0.9800141, 0.9801051]\n"
     ]
    }
   ],
   "source": [
    "metrics=evaluate_metrics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
