{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Myregressor.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    }
  },
  "cells": [
    {
      "metadata": {
        "id": "9-XP2WqfRM5s",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import pandas as pd\n",
        "import tensorflow.feature_column as fc\n",
        "import numpy as np\n",
        "# from sklearn import test_train_split\n",
        "# write an input fn as we have already written\n",
        "\n",
        "#define the feature columns\n",
        "data = pd.read_csv('algebra.csv')\n",
        "x1_norm_factor=data['Input1'].max()-data['Input1'].min()\n",
        "x2_norm_factor=data['Input2'].max()-data['Input2'].min()\n",
        "y1_norm_factor=data['Output1'].max()-data['Output1'].min()\n",
        "y2_norm_factor=data['Output2'].max()-data['Output2'].min()\n",
        "BATCH_SIZE = 128\n",
        "NUM_EPOCHS = 100\n",
        "\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "eyHBEPq-RM5z",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def get_input_3():\n",
        "    global data\n",
        "    data = data/(data.max()-data.min())\n",
        "    train_x1 = data['Input1'].values\n",
        "    train_x2 = data['Input2'].values\n",
        "    train_y1 = pd.to_numeric(data['Output1'].values, downcast = 'float')\n",
        "    dataset = tf.data.Dataset.from_tensor_slices(({'Feature1':train_x1,'Feature2':train_x2},train_y1))\n",
        "    return dataset.batch(BATCH_SIZE).repeat(NUM_EPOCHS)\n",
        "\n",
        "def get_input_4():\n",
        "    global data\n",
        "    data = data/(data.max()-data.min())\n",
        "    train_x1 = data['Input1'].values\n",
        "    train_x2 = data['Input2'].values\n",
        "    train_y2 = pd.to_numeric(data['Output2'].values, downcast = 'float')\n",
        "    dataset = tf.data.Dataset.from_tensor_slices(({'Feature1':train_x1,'Feature2':train_x2},train_y2))\n",
        "\n",
        "    return dataset.batch(BATCH_SIZE).repeat(NUM_EPOCHS)\n",
        "                                                        \n",
        "def get_input_3_4():\n",
        "    global data\n",
        "    data = data/(data.max()-data.min())\n",
        "    train_x1 = data['Input1'].values\n",
        "    train_x2 = data['Input2'].values\n",
        "    train_y1 = pd.to_numeric(data['Output1'].values, downcast = 'float')\n",
        "    train_y2 = pd.to_numeric(data['Output2'].values, downcast = 'float')\n",
        "\n",
        "    labels = list(zip(train_y1,train_y2))\n",
        "    dataset = tf.data.Dataset.from_tensor_slices(({'Feature1':train_x1,'Feature2':train_x2},labels))\n",
        "\n",
        "    return dataset.batch(BATCH_SIZE).repeat(NUM_EPOCHS)\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "mD8KG_fGRM51",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class MyDNNRegressor(tf.estimator.Estimator):  \n",
        "    def get_layer_activations(self,id):   \n",
        "        weights,bias=self.get_layer_params(id)\n",
        "        x=np.array([1.0,1.0])\n",
        "        out=np.add(np.matmul(weights,x),bias)\n",
        "        out=tf.convert_to_tensor(out)\n",
        "        out=tf.nn.relu(out)\n",
        "        sess = tf.Session()\n",
        "        with sess.as_default():\n",
        "            out = out.eval()\n",
        "            return out\n",
        "        \n",
        "        \n",
        "    def get_layer_params(self,id):\n",
        "        weights=self.get_variable_value(id+'/kernel')\n",
        "        bias=self.get_variable_value(id+'/bias')\n",
        "        return weights,bias"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "DEJ8TVtnRM53",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def my_model_3(features, labels, mode, params):\n",
        "    top = tf.feature_column.input_layer(features, params[\"feature_columns\"])\n",
        "    for units in params.get(\"hidden_units\", [20]):\n",
        "        top = tf.layers.dense(inputs=top, units=units, activation=tf.nn.relu,name=\"mylayer\")\n",
        "    output_layer = tf.layers.dense(inputs=top, units=params[\"output_units\"],name=\"output_layer\")\n",
        "    predictions = tf.squeeze(output_layer,1)\n",
        "    if mode == tf.estimator.ModeKeys.PREDICT:\n",
        "        return tf.estimator.EstimatorSpec(\n",
        "        mode=mode, predictions={\"predictions\": predictions})\n",
        "    average_loss = tf.losses.mean_squared_error(labels, predictions)\n",
        "    batch_size = tf.shape(labels)[0]\n",
        "    total_loss = tf.to_float(batch_size) * average_loss\n",
        "    if mode == tf.estimator.ModeKeys.TRAIN:\n",
        "        optimizer = params.get(\"optimizer\", tf.train.AdamOptimizer)\n",
        "        optimizer = optimizer(params.get(\"learning_rate\", None))\n",
        "        train_op = optimizer.minimize(\n",
        "            loss=average_loss, global_step=tf.train.get_global_step())\n",
        "        return tf.estimator.EstimatorSpec(\n",
        "            mode=mode, loss=total_loss, train_op=train_op)\n",
        "    assert mode == tf.estimator.ModeKeys.EVAL\n",
        "    rmse = tf.metrics.root_mean_squared_error(labels, predictions)\n",
        "    acc  = tf.metrics.accuracy(labels,predictions)\n",
        "    eval_metrics = {\"rmse\": rmse,\"accuracy\":acc}\n",
        "    return tf.estimator.EstimatorSpec(\n",
        "        mode=mode,\n",
        "        loss=total_loss,\n",
        "        eval_metric_ops=eval_metrics)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Cv-M1XbNRM56",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def my_model_4(features, labels, mode, params):\n",
        "    top = tf.feature_column.input_layer(features, params[\"feature_columns\"])\n",
        "    for units in params.get(\"hidden_units\", [20]):\n",
        "        top = tf.layers.dense(inputs=top, units=units, activation=tf.nn.relu,name=\"mylayer\")\n",
        "    output_layer = tf.layers.dense(inputs=top, units=params[\"output_units\"],name=\"output_layer\")\n",
        "    predictions = tf.squeeze(output_layer,1)\n",
        "    if mode == tf.estimator.ModeKeys.PREDICT:\n",
        "        return tf.estimator.EstimatorSpec(\n",
        "        mode=mode, predictions={\"predictions\": predictions})\n",
        "    average_loss = tf.losses.mean_squared_error(labels, predictions)\n",
        "    batch_size = tf.shape(labels)[0]\n",
        "    total_loss = tf.to_float(batch_size) * average_loss\n",
        "    if mode == tf.estimator.ModeKeys.TRAIN:\n",
        "        optimizer = params.get(\"optimizer\", tf.train.AdamOptimizer)\n",
        "        optimizer = optimizer(params.get(\"learning_rate\", None))\n",
        "        train_op = optimizer.minimize(\n",
        "            loss=average_loss, global_step=tf.train.get_global_step())\n",
        "        return tf.estimator.EstimatorSpec(\n",
        "            mode=mode, loss=total_loss, train_op=train_op)\n",
        "    assert mode == tf.estimator.ModeKeys.EVAL\n",
        "    rmse = tf.metrics.root_mean_squared_error(labels, predictions)\n",
        "    acc  = tf.metrics.accuracy(labels,predictions)\n",
        "    eval_metrics = {\"rmse\": rmse,\"accuracy\":acc}\n",
        "    return tf.estimator.EstimatorSpec(\n",
        "        mode=mode,\n",
        "        loss=total_loss,\n",
        "        eval_metric_ops=eval_metrics)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "VWZa2IH8RM58",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def my_model_34(features, labels, mode, params):\n",
        "    top = tf.feature_column.input_layer(features, params[\"feature_columns\"])\n",
        "    for units in params.get(\"hidden_units\", [20]):\n",
        "        top = tf.layers.dense(inputs=top, units=units, activation=tf.nn.relu,name=\"mylayer\")\n",
        "    output_layer = tf.layers.dense(inputs=top, units=params[\"output_units\"],name=\"output_layer\")\n",
        "    predictions = output_layer\n",
        "    if mode == tf.estimator.ModeKeys.PREDICT:\n",
        "        return tf.estimator.EstimatorSpec(\n",
        "        mode=mode, predictions={\"predictions\": predictions})\n",
        "    average_loss = tf.losses.mean_squared_error(labels, predictions)\n",
        "    batch_size = tf.shape(labels)[0]\n",
        "    total_loss = tf.to_float(batch_size) * average_loss\n",
        "    if mode == tf.estimator.ModeKeys.TRAIN:\n",
        "        optimizer = params.get(\"optimizer\", tf.train.AdamOptimizer)\n",
        "        optimizer = optimizer(params.get(\"learning_rate\", None))\n",
        "        train_op = optimizer.minimize(\n",
        "            loss=average_loss, global_step=tf.train.get_global_step())\n",
        "        return tf.estimator.EstimatorSpec(\n",
        "            mode=mode, loss=total_loss, train_op=train_op)\n",
        "    assert mode == tf.estimator.ModeKeys.EVAL\n",
        "    predictions = output_layer\n",
        "    rmse = tf.metrics.root_mean_squared_error(labels, predictions)\n",
        "    acc  = tf.metrics.accuracy(labels,predictions)\n",
        "    eval_metrics = {\"rmse\": rmse,\"accuracy\":acc}\n",
        "    return tf.estimator.EstimatorSpec(\n",
        "        mode=mode,\n",
        "        loss=total_loss,\n",
        "        eval_metric_ops=eval_metrics)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "BoCeIJLtRM5_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 445
        },
        "outputId": "0ad27eb6-658d-4cfa-c06f-bcec608de3b8"
      },
      "cell_type": "code",
      "source": [
        "#the first equation with column 3 as the output and column 1&2 as input\n",
        "feature_columns = [fc.numeric_column(key='Feature1',dtype=tf.float32),fc.numeric_column(key='Feature2',dtype=tf.float32)]\n",
        "classifier=MyDNNRegressor(\n",
        "    model_fn=my_model_4,\n",
        "    model_dir='./44',\n",
        "    params={\n",
        "        'feature_columns': feature_columns,\n",
        "        'hidden_units': [3],\n",
        "        'output_units':1,\n",
        "        \"learning_rate\": 0.001,\n",
        "        \"optimizer\": tf.train.AdamOptimizer\n",
        "    }\n",
        ")\n",
        "classifier.train(input_fn=get_input_4,steps=NUM_EPOCHS)\n",
        "metrics=classifier.evaluate(input_fn=get_input_4)\n",
        "print(\"metrics-col3-output:\",metrics)\n",
        "    "
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Using default config.\n",
            "INFO:tensorflow:Using config: {'_model_dir': './44', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': None, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f2d0f8f8748>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n",
            "INFO:tensorflow:Calling model_fn.\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "INFO:tensorflow:Create CheckpointSaverHook.\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "INFO:tensorflow:Saving checkpoints for 0 into ./44/model.ckpt.\n",
            "INFO:tensorflow:loss = 11.980504, step = 1\n",
            "INFO:tensorflow:Saving checkpoints for 100 into ./44/model.ckpt.\n",
            "INFO:tensorflow:Loss for final step: 2.6864958.\n",
            "INFO:tensorflow:Calling model_fn.\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "INFO:tensorflow:Starting evaluation at 2018-09-18-16:27:01\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Restoring parameters from ./44/model.ckpt-100\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "INFO:tensorflow:Finished evaluation at 2018-09-18-16:27:12\n",
            "INFO:tensorflow:Saving dict for global step 100: accuracy = 0.0, global_step = 100, loss = 2.887131, rmse = 0.1505456\n",
            "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 100: ./44/model.ckpt-100\n",
            "metrics-col3-output: {'accuracy': 0.0, 'loss': 2.887131, 'rmse': 0.1505456, 'global_step': 100}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "9V9AHHthRM6B",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "outputId": "21be9884-b03c-4120-dd62-23506adb056a"
      },
      "cell_type": "code",
      "source": [
        "hidden_weights,hidden_bias=classifier.get_layer_params('mylayer')\n",
        "print(\"Hidden_weights\",hidden_weights)\n",
        "print(\"Hidden_bias\",hidden_bias)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Hidden_weights [[ 0.46781093 -0.8223893   0.8388115 ]\n",
            " [-0.72959733  0.11084794 -1.116663  ]]\n",
            "Hidden_bias [-0.0790143  -0.06482318 -0.07755946]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "CN68hS_-RM6F",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        },
        "outputId": "9c1eeaaa-e0b9-4f31-9625-e75619633dac"
      },
      "cell_type": "code",
      "source": [
        "output_weights,output_bias=classifier.get_layer_params('output_layer')\n",
        "print(\"Output_weights\",output_weights)\n",
        "print(\"Output_bias\",output_bias)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Output_weights [[-0.8879254]\n",
            " [ 1.1438901]\n",
            " [-0.5722948]]\n",
            "Output_bias [0.06554074]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "xWMxpMScRM6I",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "9d2d760f-92bd-4223-e0c0-2fde8ea5ba07"
      },
      "cell_type": "code",
      "source": [
        "hidden_activation=classifier.get_layer_activations('mylayer')\n",
        "print(hidden_activation)"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1.02846759 0.        ]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "tOcVYYkjRM6M",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 516
        },
        "outputId": "47438e99-5e4c-4919-b52a-f4cec947c3ca"
      },
      "cell_type": "code",
      "source": [
        "#the second equation with column 4 as the output and column 1&2 as input\n",
        "feature_columns = [fc.numeric_column(key='Feature1',dtype=tf.float32),fc.numeric_column(key='Feature2',dtype=tf.float32)]\n",
        "classifier=MyDNNRegressor(\n",
        "    model_fn=my_model_3,\n",
        "    model_dir='./03',\n",
        "    params={\n",
        "        'feature_columns': feature_columns,\n",
        "        'hidden_units': [2],\n",
        "        'output_units':1,\n",
        "        \"learning_rate\": 0.001,\n",
        "        \"optimizer\": tf.train.AdamOptimizer\n",
        "    }\n",
        ")\n",
        "classifier.train(input_fn=get_input_3,steps=NUM_EPOCHS)\n",
        "metrics=classifier.evaluate(input_fn=get_input_3)\n",
        "print(\"metrics-col3-output:\",metrics)\n",
        "hidden_weights,hidden_bias=classifier.get_layer_params('mylayer')\n",
        "print(\"Hidden_weights\",hidden_weights)\n",
        "print(\"Hidden_bias\",hidden_bias)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Using default config.\n",
            "INFO:tensorflow:Using config: {'_model_dir': './03', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': None, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7fca789d31d0>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n",
            "INFO:tensorflow:Calling model_fn.\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "INFO:tensorflow:Create CheckpointSaverHook.\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Restoring parameters from ./03/model.ckpt-100\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "INFO:tensorflow:Saving checkpoints for 100 into ./03/model.ckpt.\n",
            "INFO:tensorflow:loss = 4.993519, step = 101\n",
            "INFO:tensorflow:Saving checkpoints for 200 into ./03/model.ckpt.\n",
            "INFO:tensorflow:Loss for final step: 2.6839747.\n",
            "INFO:tensorflow:Calling model_fn.\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "INFO:tensorflow:Starting evaluation at 2018-09-18-16:39:53\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Restoring parameters from ./03/model.ckpt-200\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "INFO:tensorflow:Finished evaluation at 2018-09-18-16:40:04\n",
            "INFO:tensorflow:Saving dict for global step 200: accuracy = 0.0, global_step = 200, loss = 2.9874594, rmse = 0.15313901\n",
            "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 200: ./03/model.ckpt-200\n",
            "metrics-col3-output: {'accuracy': 0.0, 'loss': 2.9874594, 'rmse': 0.15313901, 'global_step': 200}\n",
            "Hidden_weights [[-0.7553347  -1.0097673 ]\n",
            " [ 0.27366415 -0.6654497 ]]\n",
            "Hidden_bias [0.22309995 0.        ]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Ys-MHWH8RM6S",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "outputId": "20797606-0609-4f2d-d705-016f302f334a"
      },
      "cell_type": "code",
      "source": [
        "output_weights,output_bias=classifier.get_layer_params('output_layer')\n",
        "print(\"Output_weights\",output_weights)\n",
        "print(\"Output_bias\",output_bias)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Output_weights [[-1.1394113]\n",
            " [ 0.3539226]]\n",
            "Output_bias [0.0779909]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "PcUqbL8VRM6V",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "6929d3dc-e086-41cb-9a1b-01751d4d78f8"
      },
      "cell_type": "code",
      "source": [
        "hidden_activation=classifier2.get_layer_activations('mylayer')\n",
        "print(hidden_activation)"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1.04871748 0.        ]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "TJi_acwqRM6Z",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 428
        },
        "outputId": "2ca02508-9cf7-4ab5-a8f7-6a83fed3e12f"
      },
      "cell_type": "code",
      "source": [
        "#the third problem with column 3&4 as the output and column 1&2 as input\n",
        "feature_columns = [fc.numeric_column(key='Feature1',dtype=tf.float32),fc.numeric_column(key='Feature2',dtype=tf.float32)]\n",
        "classifier=MyDNNRegressor(\n",
        "    model_fn=my_model_34,\n",
        "    model_dir='./343',\n",
        "    params={\n",
        "        'feature_columns': feature_columns,\n",
        "        # Two hidden layers of 10 nodes each.\n",
        "        'hidden_units': [3],\n",
        "        # The model must choose between 3 classes.\n",
        "        'output_units':2,\n",
        "        \"learning_rate\": 0.001,\n",
        "        \"optimizer\": tf.train.AdamOptimizer\n",
        "    }\n",
        ")\n",
        "classifier.train(input_fn=get_input_3_4,steps=NUM_EPOCHS)\n",
        "metrics=classifier.evaluate(input_fn=get_input_3_4)\n",
        "print(\"metrics-col343-output:\",metrics)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Using default config.\n",
            "INFO:tensorflow:Using config: {'_model_dir': './343', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': None, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7fca793ce1d0>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n",
            "INFO:tensorflow:Calling model_fn.\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "INFO:tensorflow:Create CheckpointSaverHook.\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "INFO:tensorflow:Saving checkpoints for 0 into ./343/model.ckpt.\n",
            "INFO:tensorflow:loss = 11.212599, step = 1\n",
            "INFO:tensorflow:Saving checkpoints for 100 into ./343/model.ckpt.\n",
            "INFO:tensorflow:Loss for final step: 5.7584815.\n",
            "INFO:tensorflow:Calling model_fn.\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "INFO:tensorflow:Starting evaluation at 2018-09-18-16:33:20\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Restoring parameters from ./343/model.ckpt-100\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "INFO:tensorflow:Finished evaluation at 2018-09-18-16:33:31\n",
            "INFO:tensorflow:Saving dict for global step 100: accuracy = 0.0, global_step = 100, loss = 5.7023387, rmse = 0.21157354\n",
            "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 100: ./343/model.ckpt-100\n",
            "metrics-col343-output: {'accuracy': 0.0, 'loss': 5.7023387, 'rmse': 0.21157354, 'global_step': 100}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "uUHfNqQBRM6e",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "126dd519-2358-46fd-99ae-9062e10521a5"
      },
      "cell_type": "code",
      "source": [
        "hidden_weights,hidden_bias=classifier.get_layer_params('mylayer')\n",
        "print(\"Hidden_weights\",hidden_weights)\n",
        "print(\"Hidden_bias\",hidden_bias)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Hidden_weights [[-0.40600175 -0.8305598   0.7578669 ]\n",
            " [-0.6333935   0.4068953  -0.5944415 ]]\n",
            "Hidden_bias [ 0.         -0.08481121 -0.08135027]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "H-VxCmt1RM6h",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "c8484c9f-d6c4-477b-a01f-b03f9a77aa68"
      },
      "cell_type": "code",
      "source": [
        "output_weights,output_bias=classifier.get_layer_params('output_layer')\n",
        "print(\"Output_weights\",output_weights)\n",
        "print(\"Output_bias\",output_bias)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Output_weights [[ 0.24737692  0.10847652]\n",
            " [ 0.66898364 -0.26196858]\n",
            " [-0.37944865 -0.63974375]]\n",
            "Output_bias [0.03890631 0.06793098]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "hHpNvGaYRM6l",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "faaf401a-e48b-4c5a-be51-4e8ff17abaf7"
      },
      "cell_type": "code",
      "source": [
        "hidden_activation=classifier3.get_layer_activations('mylayer')\n",
        "print(hidden_activation)"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1.04871748 0.        ]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "muEPbhbfRM6q",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# zero_inp=tf.estimator.inputs.numpy_input_fn(x = {'Feature1':np.array([0.0],dtype = np.float32),'Feature2':np.array([0.0],dtype = np.float32)}, shuffle = False)\n",
        "# one_inp = tf.estimator.inputs.numpy_input_fn(x = {'Feature1':np.array([1.0],dtype = np.float32),'Feature2':np.array([1.0],dtype = np.float32)}, shuffle = False)\n",
        "# bias=list(classifier.predict(zero_inp))[0]['predictions']\n",
        "# one_inp_with_bias = list(classifier.predict(one_inp))[0]['predictions']\n",
        "# print(\"a1, a2 ---> \",[one_inp_with_bias[0]-bias[0],one_inp_with_bias[1]-bias[1]])\n",
        "# print(\"b1, b2 ---> \",bias)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "qgGdSo_nRM6s",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Incomplete!!\n",
        "def guess_equation(x1,x2):\n",
        "    inp_1=x1/x1_norm_factor\n",
        "    inp_2=x2/x2_norm_factor\n",
        "    ex1=tf.estimator.inputs.numpy_input_fn(x = {'Feature1':np.array([inp_1],dtype = np.float32),'Feature2':np.array([inp2],dtype = np.float32)}, shuffle = False)\n",
        "    y1=classifier1.predict(ex1)\n",
        "    \n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}